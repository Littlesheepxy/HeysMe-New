import { openai } from "@ai-sdk/openai"
import { anthropic } from "@ai-sdk/anthropic"
import { bedrock } from "@ai-sdk/amazon-bedrock"
import { createOpenAI } from "@ai-sdk/openai"
import { generateText, generateObject, streamText } from "ai"
import type { ModelProvider } from "@/types/models"
import { getClaude4ModelId, validateClaude4Config } from "./bedrock-config"

// æ™ºè°±AIé…ç½®
const zhipuAI = createOpenAI({
  baseURL: process.env.ZHIPU_BASE_URL || 'https://open.bigmodel.cn/api/paas/v4/',
  apiKey: process.env.ZHIPU_API_KEY || '',
  name: 'zhipu',
})

// éªŒè¯ API keys æ˜¯å¦é…ç½®
function validateApiKeys() {
  const openaiKey = process.env.OPENAI_API_KEY
  const anthropicKey = process.env.ANTHROPIC_API_KEY
  const awsAccessKey = process.env.AWS_ACCESS_KEY_ID
  const awsSecretKey = process.env.AWS_SECRET_ACCESS_KEY
  const zhipuKey = process.env.ZHIPU_API_KEY

  console.log("ğŸ”‘ API Keys status:")
  console.log("- OpenAI:", openaiKey ? `âœ… Configured (${openaiKey.substring(0, 10)}...)` : "âŒ Missing")
  console.log("- Anthropic:", anthropicKey ? `âœ… Configured (${anthropicKey.substring(0, 10)}...)` : "âŒ Missing")
  console.log("- AWS Bedrock:", (awsAccessKey && awsSecretKey) ? `âœ… Configured` : "âŒ Missing")
  console.log("- æ™ºè°±AI:", zhipuKey ? `âœ… Configured (${zhipuKey.substring(0, 10)}...)` : "âŒ Missing")

  return { 
    openaiKey, 
    anthropicKey, 
    awsAccessKey, 
    awsSecretKey, 
    zhipuKey,
    hasAws: !!(awsAccessKey && awsSecretKey)
  }
}

export function getModelClient(provider: ModelProvider, modelId: string) {
  const { openaiKey, anthropicKey, hasAws, zhipuKey } = validateApiKeys()

  switch (provider) {
    case "openai":
      if (!openaiKey) {
        throw new Error("OpenAI API key is not configured. Please set OPENAI_API_KEY in your environment variables.")
      }
      console.log(`ğŸ¤– Creating OpenAI client with model: ${modelId}`)
      return openai(modelId)
      
    case "claude":
      if (!anthropicKey) {
        throw new Error(
          "Anthropic API key is not configured. Please set ANTHROPIC_API_KEY in your environment variables.",
        )
      }
      console.log(`ğŸ¤– Creating Anthropic client with model: ${modelId}`)
      return anthropic(modelId)
      
    case "bedrock":
      if (!hasAws) {
        throw new Error(
          "AWS credentials are not configured. Please set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY in your environment variables.",
        )
      }
      
      // å¯¹äº Claude 4ï¼Œä½¿ç”¨æ™ºèƒ½æ¨¡å‹IDé€‰æ‹©
      let actualModelId = modelId
      if (modelId === "anthropic.claude-sonnet-4-20250514-v1:0") {
        actualModelId = getClaude4ModelId()
        const claude4Config = validateClaude4Config()
        if (!claude4Config.isValid) {
          console.warn(`âš ï¸ ${claude4Config.message}`)
          claude4Config.recommendations.forEach(rec => console.warn(`  ${rec}`))
        }
      }
      
      console.log(`ğŸ¤– Creating AWS Bedrock client with model: ${actualModelId}`)
      return bedrock(actualModelId)
      
    case "zhipu":
      if (!zhipuKey) {
        throw new Error(
          "æ™ºè°±AI API key is not configured. Please set ZHIPU_API_KEY in your environment variables.",
        )
      }
      console.log(`ğŸ¤– Creating æ™ºè°±AI client with model: ${modelId}`)
      return zhipuAI(modelId)
      
    default:
      throw new Error(`Unsupported model provider: ${provider}`)
  }
}

export async function generateWithModel(
  provider: ModelProvider,
  modelId: string,
  input: string | Array<{ role: 'system' | 'user' | 'assistant', content: string }>,
  options?: {
    system?: string
    schema?: any
    maxTokens?: number
  },
) {
  try {
    console.log(`\nğŸš€ [Model] å¼€å§‹ç”Ÿæˆ - Provider: ${provider}, Model: ${modelId}`);
    const model = getModelClient(provider, modelId)

    // ğŸ†• å¤„ç†è¾“å…¥ç±»å‹
    const isMessagesMode = Array.isArray(input);
    
    console.log(`ğŸ“Š [è¾“å…¥åˆ†æ]`, {
      mode: isMessagesMode ? 'messages' : 'prompt',
      inputLength: isMessagesMode ? input.length : (input as string).length,
      hasSchema: !!options?.schema,
      hasSystem: !!options?.system,
      maxTokens: options?.maxTokens
    });
    
    if (isMessagesMode) {
      console.log(`ğŸ’¬ [Messagesæ¨¡å¼] ä½¿ç”¨å¯¹è¯å†å²ï¼Œæ¶ˆæ¯æ•°: ${input.length}`);
      (input as any[]).forEach((msg, index) => {
        const roleIcon = msg.role === 'user' ? 'ğŸ‘¤' : msg.role === 'assistant' ? 'ğŸ¤–' : 'ğŸ“';
        const roleName = msg.role === 'user' ? 'ç”¨æˆ·' : msg.role === 'assistant' ? 'åŠ©æ‰‹' : 'ç³»ç»Ÿ';
        console.log(`  ${roleIcon} [${roleName}${index}] ${msg.content?.substring(0, 150)}...`);
      });
    } else {
      console.log(`ğŸ“ [Promptæ¨¡å¼] ä½¿ç”¨å•æ¬¡æç¤ºï¼Œé•¿åº¦: ${(input as string).length}`);
      console.log(`ğŸ“„ [Promptå†…å®¹] ${(input as string).substring(0, 200)}...`);
    }

    if (options?.schema) {
      console.log(`ğŸ”§ [ç»“æ„åŒ–è¾“å‡º] ä½¿ç”¨ generateObject`);
      // ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
      const requestParams: any = {
        model,
        prompt: isMessagesMode ? undefined : input as string,
        messages: isMessagesMode ? input as any : undefined, // ğŸ†• æ”¯æŒ messages
        system: isMessagesMode ? undefined : options.system, // messages æ¨¡å¼ä¸‹ system å·²åŒ…å«åœ¨ messages ä¸­
        schema: options.schema,
      }
      
      // è®¾ç½® maxTokensï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼ˆè€ƒè™‘APIé™åˆ¶ï¼‰
      requestParams.maxTokens = options.maxTokens || 8000
      
      const result = await generateObject(requestParams)
      console.log(`âœ… [ç”ŸæˆæˆåŠŸ] ç»“æ„åŒ–å¯¹è±¡ç”Ÿæˆå®Œæˆ (Provider: ${provider})`);
      console.log(`ğŸ“Š [ç»“æœç»Ÿè®¡] å¯¹è±¡å­—æ®µæ•°: ${result.object && typeof result.object === 'object' ? Object.keys(result.object as object).length : 0}`);
      return result
    } else {
      console.log(`ğŸ“ [æ–‡æœ¬è¾“å‡º] ä½¿ç”¨ generateText`);
      // ä½¿ç”¨æ–‡æœ¬ç”Ÿæˆ
      const requestParams: any = {
        model,
        prompt: isMessagesMode ? undefined : input as string,
        messages: isMessagesMode ? input as any : undefined, // ğŸ†• æ”¯æŒ messages
        system: isMessagesMode ? undefined : options?.system, // messages æ¨¡å¼ä¸‹ system å·²åŒ…å«åœ¨ messages ä¸­
      }
      
      // è®¾ç½® maxTokensï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼ˆè€ƒè™‘APIé™åˆ¶ï¼‰
      requestParams.maxTokens = options?.maxTokens || 8000
      
      const result = await generateText(requestParams)
      console.log(`âœ… [ç”ŸæˆæˆåŠŸ] æ–‡æœ¬ç”Ÿæˆå®Œæˆ (Provider: ${provider})`);
      console.log(`ğŸ“Š [ç»“æœç»Ÿè®¡] æ–‡æœ¬é•¿åº¦: ${result.text.length}`);
      return result
    }
  } catch (error) {
    console.error(`âŒ [ç”Ÿæˆå¤±è´¥] ${provider} model ${modelId} é”™è¯¯:`, {
      error: error instanceof Error ? error.message : error,
      inputType: Array.isArray(input) ? 'messages' : 'prompt',
      hasSchema: !!options?.schema
    })

    // æ™ºèƒ½æ¨¡å‹å›é€€
    await attemptModelFallback(provider, input, options)

    throw error
  }
}

// æµ‹è¯• API è¿æ¥
export async function testModelConnection(provider: ModelProvider, modelId: string) {
  try {
    console.log(`ğŸ§ª Testing connection for ${provider} - ${modelId}`)

    const result = await generateWithModel(provider, modelId, "Hello, this is a test message.", {
      system: "You are a helpful assistant. Respond briefly with just 'Test successful'.",
      maxTokens: 10,
    })

    const response = 'text' in result ? result.text : 'object' in result ? JSON.stringify(result.object) : "No response"

    console.log(`âœ… Test successful for ${provider} - ${modelId}:`, response)

    return {
      success: true,
      provider,
      modelId,
      response: response.substring(0, 100), // é™åˆ¶å“åº”é•¿åº¦
      timestamp: new Date().toISOString(),
    }
  } catch (error) {
    console.error(`âŒ Test failed for ${provider} - ${modelId}:`, error)

    return {
      success: false,
      provider,
      modelId,
      error: error instanceof Error ? error.message : "Unknown error",
      errorType: error instanceof Error ? error.constructor.name : typeof error,
      timestamp: new Date().toISOString(),
    }
  }
}

// ä¾¿æ·å‡½æ•°ï¼šä½¿ç”¨ GPT-4o
export async function generateWithGPT4o(
  input: string | Array<{ role: 'system' | 'user' | 'assistant', content: string }>,
  options?: {
    system?: string
    schema?: any
    maxTokens?: number
  },
) {
  return generateWithModel("openai", "gpt-4o", input, options)
}

// æ™ºèƒ½æ¨¡å‹å›é€€å‡½æ•°
async function attemptModelFallback(
  failedProvider: ModelProvider,
  input: string | Array<{ role: 'system' | 'user' | 'assistant', content: string }>,
  options?: {
    system?: string
    schema?: any
    maxTokens?: number
  }
) {
  const { openaiKey, anthropicKey, hasAws, zhipuKey } = validateApiKeys()
  
  // å®šä¹‰å›é€€é¡ºåº - Claude API ä¼˜å…ˆ
  const fallbackOrder: Array<{provider: ModelProvider, model: string, available: boolean}> = [
    { provider: "claude", model: "claude-sonnet-4-20250514", available: !!anthropicKey },
    { provider: "openai", model: "gpt-4o", available: !!openaiKey },
    { provider: "bedrock", model: "anthropic.claude-sonnet-4-20250514-v1:0", available: hasAws },
    { provider: "zhipu", model: "glm-4.5", available: !!zhipuKey },
  ]
  
  // è¿‡æ»¤æ‰å¤±è´¥çš„æä¾›å•†å’Œä¸å¯ç”¨çš„æä¾›å•†
  const availableFallbacks = fallbackOrder.filter(
    fallback => fallback.provider !== failedProvider && fallback.available
  )
  
  for (const fallback of availableFallbacks) {
    console.log(`ğŸ”„ [æ¨¡å‹å›é€€] ${failedProvider} å¤±è´¥ï¼Œå°è¯•å›é€€åˆ° ${fallback.provider}...`)
    try {
      return await generateWithModel(fallback.provider, fallback.model, input, options)
    } catch (fallbackError) {
      console.error(`âŒ [å›é€€å¤±è´¥] ${fallback.provider} å›é€€ä¹Ÿå¤±è´¥:`, fallbackError)
    }
  }
  
  console.error(`âŒ [å›é€€å®Œå…¨å¤±è´¥] æ‰€æœ‰å¯ç”¨æ¨¡å‹éƒ½å¤±è´¥äº†`)
}

// ä¾¿æ·å‡½æ•°ï¼šä½¿ç”¨ Claude 4 Sonnet
export async function generateWithClaude(
  input: string | Array<{ role: 'system' | 'user' | 'assistant', content: string }>,
  options?: {
    system?: string
    schema?: any
    maxTokens?: number
  },
) {
  return generateWithModel("claude", "claude-sonnet-4-20250514", input, options)
}

// ä¾¿æ·å‡½æ•°ï¼šä½¿ç”¨ AWS Bedrock Claude
export async function generateWithBedrockClaude(
  input: string | Array<{ role: 'system' | 'user' | 'assistant', content: string }>,
  options?: {
    system?: string
    schema?: any
    maxTokens?: number
  },
) {
  return generateWithModel("bedrock", "anthropic.claude-sonnet-4-20250514-v1:0", input, options)
}

// ä¾¿æ·å‡½æ•°ï¼šä½¿ç”¨æ™ºè°±AI
export async function generateWithZhipu(
  input: string | Array<{ role: 'system' | 'user' | 'assistant', content: string }>,
  options?: {
    system?: string
    schema?: any
    maxTokens?: number
  },
) {
  return generateWithModel("zhipu", "glm-4.5", input, options)
}

// æ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼šæŒ‰ä¼˜å…ˆçº§å°è¯•å¯ç”¨çš„æ¨¡å‹
export async function generateWithBestAvailableModel(
  input: string | Array<{ role: 'system' | 'user' | 'assistant', content: string }>,
  options?: {
    system?: string
    schema?: any
    maxTokens?: number
  },
) {
  const { openaiKey, anthropicKey, hasAws, zhipuKey } = validateApiKeys()

  // æŒ‰ä¼˜å…ˆçº§é¡ºåºå°è¯•æ¨¡å‹ - Claude API ä¼˜å…ˆ
  const modelPriority = [
    { provider: "claude" as ModelProvider, model: "claude-sonnet-4-20250514", available: !!anthropicKey },
    { provider: "openai" as ModelProvider, model: "gpt-4o", available: !!openaiKey },
    { provider: "bedrock" as ModelProvider, model: "anthropic.claude-sonnet-4-20250514-v1:0", available: hasAws },
    { provider: "zhipu" as ModelProvider, model: "glm-4.5", available: !!zhipuKey },
  ]

  for (const model of modelPriority) {
    if (model.available) {
      try {
        console.log(`ğŸ¯ [æ™ºèƒ½é€‰æ‹©] å°è¯•ä½¿ç”¨ ${model.provider} - ${model.model}`)
        return await generateWithModel(model.provider, model.model, input, options)
      } catch (error) {
        console.log(`âŒ [æ™ºèƒ½é€‰æ‹©] ${model.provider} å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...`)
        continue
      }
    }
  }

  throw new Error(
    "No API keys configured or all models failed. Please configure at least one: ANTHROPIC_API_KEY, OPENAI_API_KEY, ZHIPU_API_KEY, or AWS credentials."
  )
}

export async function* generateStreamWithModel(
  provider: ModelProvider,
  modelId: string,
  input: string | Array<{ role: 'system' | 'user' | 'assistant', content: string }>,
  options?: {
    system?: string
    maxTokens?: number
    tools?: Record<string, any> | Array<{
      name: string;
      description: string;
      input_schema: {
        type: string;
        properties: Record<string, any>;
        required: string[];
      };
    }>;
  },
): AsyncGenerator<string, void, unknown> {
  try {
    console.log(`\nğŸŒŠ [Stream] å¼€å§‹æµå¼ç”Ÿæˆ - Provider: ${provider}, Model: ${modelId}`);
    const model = getModelClient(provider, modelId)

    // ğŸ†• å¤„ç†è¾“å…¥ç±»å‹
    const isMessagesMode = Array.isArray(input);
    
    console.log(`ğŸ“Š [æµå¼è¾“å…¥åˆ†æ]`, {
      mode: isMessagesMode ? 'messages' : 'prompt',
      inputLength: isMessagesMode ? input.length : (input as string).length,
      maxTokens: options?.maxTokens,
      hasTools: !!options?.tools,
      toolsCount: options?.tools?.length || 0
    });
    
    console.log(`ğŸŒŠ [æµå¼æ–‡æœ¬] ä½¿ç”¨ streamText${options?.tools ? ' (with tools)' : ''}`);
    
    // ğŸ†• å‡†å¤‡å·¥å…·å‚æ•°
    const streamTextParams: any = {
      model,
      prompt: isMessagesMode ? undefined : input as string,
      messages: isMessagesMode ? input as any : undefined,
      system: isMessagesMode ? undefined : options?.system,
      maxTokens: options?.maxTokens || 8000,
    };
    
    // ğŸ†• æ·»åŠ å·¥å…·æ”¯æŒ
    if (options?.tools) {
      if (Array.isArray(options.tools)) {
        // æ—§æ ¼å¼å·¥å…·ï¼ˆæ•°ç»„æ ¼å¼ï¼‰
        console.log(`ğŸ”§ [å·¥å…·æ”¯æŒ] æ·»åŠ  ${options.tools.length} ä¸ªå·¥å…·åˆ°è¯·æ±‚ä¸­`);
        options.tools.forEach((tool, index) => {
          console.log(`  ğŸ› ï¸ [å·¥å…·${index + 1}] ${tool.name}: ${tool.description}`);
        });
        streamTextParams.tools = options.tools;
      } else {
        // æ–°æ ¼å¼å·¥å…·ï¼ˆå¯¹è±¡æ ¼å¼ï¼Œai-sdkæ ‡å‡†ï¼‰
        const toolCount = Object.keys(options.tools).length;
        console.log(`ğŸ”§ [å·¥å…·æ”¯æŒ] æ·»åŠ  ${toolCount} ä¸ªai-sdkæ ‡å‡†å·¥å…·åˆ°è¯·æ±‚ä¸­`);
        Object.entries(options.tools).forEach(([name, tool], index) => {
          console.log(`  ğŸ› ï¸ [å·¥å…·${index + 1}] ${name}: ${tool.description || 'æ— æè¿°'}`);
        });
        streamTextParams.tools = options.tools;
      }
    }
    
    // ä½¿ç”¨æµå¼æ–‡æœ¬ç”Ÿæˆ
    console.log(`ğŸ“¡ [APIè°ƒç”¨] å‡†å¤‡è°ƒç”¨ streamText...`);
    const result = await streamText(streamTextParams)

    console.log(`âœ… [æµå¼å¼€å§‹] æ–‡æœ¬æµå¼ç”Ÿæˆå¼€å§‹ (Provider: ${provider})`);
    
    let chunkCount = 0;
    let toolCallCount = 0;
    
    // ğŸ†• å¤„ç†å®Œæ•´çš„æµå¼å“åº”ï¼ˆåŒ…æ‹¬å·¥å…·è°ƒç”¨ï¼‰
    for await (const delta of result.fullStream) {
      console.log(`ğŸ” [æµå¼Deltaç±»å‹] ${delta.type}`);
      
      if (delta.type === 'text-delta') {
        chunkCount++;
        console.log(`ğŸ“¤ [æ–‡æœ¬å—] ç¬¬${chunkCount}ä¸ªï¼Œé•¿åº¦: ${delta.text.length}`);
        yield delta.text;
      } else if (delta.type === 'tool-call') {
        toolCallCount++;
        console.log(`ğŸ› ï¸ [å·¥å…·è°ƒç”¨] ç¬¬${toolCallCount}ä¸ª: ${delta.toolName}`);
        const toolCallText = `[è°ƒç”¨å·¥å…·: ${delta.toolName}]`;
        yield toolCallText;
      } else if (delta.type === 'tool-result') {
        console.log(`ğŸ”§ [å·¥å…·ç»“æœ]`);
        const toolResultText = `[å·¥å…·æ‰§è¡Œå®Œæˆ]`;
        yield toolResultText;
      } else {
        console.log(`â“ [æœªçŸ¥Deltaç±»å‹] ${delta.type}:`, delta);
      }
    }
    
    console.log(`âœ… [æµå¼å®Œæˆ] æ–‡æœ¬æµå¼ç”Ÿæˆå®Œæˆ (Provider: ${provider})ï¼Œæ–‡æœ¬å—æ•°: ${chunkCount}ï¼Œå·¥å…·è°ƒç”¨æ•°: ${toolCallCount}`);

  } catch (error) {
    console.error(`âŒ [æµå¼å¤±è´¥] ${provider} model ${modelId} é”™è¯¯:`, {
      error: error instanceof Error ? error.message : error,
      inputType: Array.isArray(input) ? 'messages' : 'prompt'
    })

    // æ™ºèƒ½å›é€€é€»è¾‘ - æ ¹æ®å½“å‰å¤±è´¥çš„æä¾›å•†é€‰æ‹©æœ€ä¼˜å›é€€
    const { openaiKey, anthropicKey, hasAws, zhipuKey } = validateApiKeys()
    
    const fallbackOptions = [
      { provider: "claude" as ModelProvider, model: "claude-sonnet-4-20250514", available: !!anthropicKey },
      { provider: "openai" as ModelProvider, model: "gpt-4o", available: !!openaiKey },
      { provider: "bedrock" as ModelProvider, model: "anthropic.claude-sonnet-4-20250514-v1:0", available: hasAws },
      { provider: "zhipu" as ModelProvider, model: "glm-4.5", available: !!zhipuKey },
    ].filter(option => option.provider !== provider && option.available)
    
    for (const fallback of fallbackOptions) {
      console.log(`ğŸ”„ [æµå¼å›é€€] ${provider} å¤±è´¥ï¼Œå°è¯•å›é€€åˆ° ${fallback.provider}...`)
      try {
        yield* generateStreamWithModel(fallback.provider, fallback.model, input, options)
        return
      } catch (fallbackError) {
        console.error(`âŒ [æµå¼å›é€€å¤±è´¥] ${fallback.provider} å›é€€ä¹Ÿå¤±è´¥:`, fallbackError)
      }
    }

    throw error
  }
}
