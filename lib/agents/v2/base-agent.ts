/**
 * åŸºäº Vercel AI SDK çš„æ–°ä¸€ä»£ Agent åŸºç±»
 * ç»Ÿä¸€çš„å¤šæ­¥éª¤å·¥å…·è°ƒç”¨å’Œæµå¼å“åº”å¤„ç†
 */

import { anthropic } from '@ai-sdk/anthropic';
import { generateText, tool, stepCountIs, ModelMessage } from 'ai';
import { z } from 'zod';

export interface AgentCapabilities {
  canStream: boolean;
  canUseTools: boolean;
  canAnalyzeCode: boolean;
  canGenerateCode: boolean;
  canAccessFiles: boolean;
  canAccessInternet: boolean;
  canRememberContext: boolean;
  maxContextLength: number;
  supportedLanguages: string[];
  specializedFor: string[];
}

export interface StreamableAgentResponse {
  immediate_display: {
    reply: string;
    agent_name: string;
    timestamp: string;
  };
  system_state: {
    intent: string;
    done: boolean;
    progress?: number;
    current_stage?: string;
    next_agent?: string;
    metadata?: Record<string, any>;
  };
}

export interface SessionData {
  id: string;
  userId: string;
  createdAt: Date;
  updatedAt: Date;
  metadata?: Record<string, any>;
}

export interface ToolDefinition {
  name: string;
  description: string;
  inputSchema: z.ZodSchema;
  execute: (params: any) => Promise<any>;
}

export abstract class BaseAgentV2 {
  protected name: string;
  protected id: string;
  protected capabilities: AgentCapabilities;
  protected conversationHistory = new Map<string, Array<{ role: 'user' | 'assistant'; content: string }>>();

  constructor(name: string, id: string, capabilities: AgentCapabilities) {
    this.name = name;
    this.id = id;
    this.capabilities = capabilities;
  }

  /**
   * ä¸»è¦å¤„ç†æ–¹æ³• - å­ç±»å¿…é¡»å®ç°
   */
  abstract processRequest(
    userInput: string,
    sessionData: SessionData,
    context?: Record<string, any>
  ): AsyncGenerator<StreamableAgentResponse, void, unknown>;

  /**
   * è·å–å·¥å…·å®šä¹‰ - å­ç±»å¿…é¡»å®ç°
   */
  abstract getTools(): Record<string, ToolDefinition>;

  /**
   * æ ¸å¿ƒå¤šæ­¥éª¤å·¥å…·è°ƒç”¨æ–¹æ³•
   */
  protected async executeMultiStepWorkflow(
    userInput: string,
    sessionData: SessionData,
    systemPrompt: string,
    maxSteps: number = 6,
    onStepComplete?: (stepNumber: number, toolResults: any[]) => Promise<void>
  ): Promise<{
    text: string;
    toolCalls: any[];
    toolResults: any[];
    steps: any[];
    usage?: any;
  }> {
    // æ„å»ºå¯¹è¯å†å²
    const conversationHistory = this.conversationHistory.get(sessionData.id) || [];
    const messages: ModelMessage[] = [
      {
        role: 'system',
        content: systemPrompt
      },
      ...conversationHistory.map(msg => ({
        role: msg.role,
        content: msg.content
      })),
      {
        role: 'user',
        content: userInput
      }
    ];

    // è½¬æ¢å·¥å…·å®šä¹‰ä¸º Vercel AI SDK æ ¼å¼
    const tools = this.convertToolsToVercelFormat();

    // æ‰§è¡Œå¤šæ­¥éª¤å·¥å…·è°ƒç”¨
    const result = await generateText({
      model: anthropic('claude-3-5-sonnet-20241022'),
      messages,
      tools,
      stopWhen: stepCountIs(maxSteps),
      temperature: 0.7,
      maxTokens: 8000,
      onStepFinish: async ({ toolResults, stepNumber }) => {
        console.log(`ğŸ“Š [æ­¥éª¤ ${stepNumber}] å®Œæˆï¼Œæ‰§è¡Œäº† ${toolResults.length} ä¸ªå·¥å…·`);
        if (onStepComplete) {
          await onStepComplete(stepNumber, toolResults);
        }
      }
    });

    return result;
  }

  /**
   * è½¬æ¢å·¥å…·å®šä¹‰ä¸º Vercel AI SDK æ ¼å¼
   */
  private convertToolsToVercelFormat(): Record<string, any> {
    const tools = this.getTools();
    const vercelTools: Record<string, any> = {};

    for (const [name, toolDef] of Object.entries(tools)) {
      vercelTools[name] = tool({
        description: toolDef.description,
        inputSchema: toolDef.inputSchema,
        execute: toolDef.execute
      });
    }

    return vercelTools;
  }

  /**
   * åˆ›å»ºæ ‡å‡†å“åº”
   */
  protected createResponse(response: Partial<StreamableAgentResponse>): StreamableAgentResponse {
    return {
      immediate_display: {
        reply: response.immediate_display?.reply || '',
        agent_name: this.name,
        timestamp: new Date().toISOString(),
        ...response.immediate_display
      },
      system_state: {
        intent: 'processing',
        done: false,
        ...response.system_state
      }
    };
  }

  /**
   * åˆ›å»ºæ€è€ƒå“åº”
   */
  protected createThinkingResponse(message: string, progress: number): StreamableAgentResponse {
    return this.createResponse({
      immediate_display: {
        reply: message
      },
      system_state: {
        intent: 'thinking',
        done: false,
        progress,
        current_stage: 'åˆ†æä¸­'
      }
    });
  }

  /**
   * æ›´æ–°å¯¹è¯å†å²
   */
  protected updateConversationHistory(sessionData: SessionData, userInput: string, assistantResponse: string): void {
    if (!this.conversationHistory.has(sessionData.id)) {
      this.conversationHistory.set(sessionData.id, []);
    }

    const history = this.conversationHistory.get(sessionData.id)!;
    history.push(
      { role: 'user', content: userInput },
      { role: 'assistant', content: assistantResponse }
    );

    // ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
    if (history.length > 20) {
      history.splice(0, history.length - 20);
    }
  }

  /**
   * é”™è¯¯å¤„ç†
   */
  protected async handleError(
    error: Error,
    sessionData: SessionData,
    context?: Record<string, any>
  ): Promise<StreamableAgentResponse> {
    console.error(`âŒ [${this.name}] å¤„ç†å¤±è´¥:`, error);
    
    return this.createResponse({
      immediate_display: {
        reply: 'æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·ç¨åé‡è¯•ã€‚'
      },
      system_state: {
        intent: 'error',
        done: true,
        metadata: {
          error: error.message,
          timestamp: new Date().toISOString()
        }
      }
    });
  }

  /**
   * è·å– Agent ä¿¡æ¯
   */
  getInfo() {
    return {
      name: this.name,
      id: this.id,
      capabilities: this.capabilities
    };
  }
}
